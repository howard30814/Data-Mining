{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment3 Text mining\n",
    "## Dataset Chinese text dataset ：\n",
    "####       數據檔中包含10同類型的目錄，每個目錄裡面有一個代表的新聞主題，如\"0體育\"，\"1房屋\"，\"2社會\"，\"3星座\"等等，在不同主題中各有1000個文本資料，而我的學號後四碼為5422，因此我選擇：\"5娛樂\"，\"4科技\"，\"2社會\"，進行我這次的文字探勘。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 匯入需要的套件&在開放資源找到的4種停字詞表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#加载停用词\n",
    "stopwords1=pd.read_csv('中文停用词表.txt',index_col=False,quoting=3,sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "stopwords2=pd.read_csv('四川大学机器智能实验室停用词库.txt',index_col=False,quoting=3,sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "stopwords3=pd.read_csv('百度停用词表.txt',index_col=False,quoting=3,sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "stopwords4=pd.read_csv('哈工大停用词表.txt',index_col=False,quoting=3,sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "st=pd.concat([stopwords1,stopwords2,stopwords3,stopwords4])\n",
    "stopwords=st.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 匯入OS模塊，運用來建立文件，刪除文件，查詢文件等。\n",
    "#### 匯入三種所需文字文本：\"5娛樂\"，\"4科技\"，\"2社會\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '5娛樂/'\n",
    "lines1 =[]\n",
    "for filename in os.listdir(path):\n",
    "    if os.path.isfile(path + filename) and filename.endswith(\".txt\"):\n",
    "        with open(path + filename, \"r\", encoding= 'utf-8') as file:\n",
    "            data = file.read()\n",
    "            lines1.append(data                    \n",
    "\n",
    "path = '4科技/'\n",
    "lines2 =[]\n",
    "for filename in os.listdir(path):\n",
    "    if os.path.isfile(path + filename) and filename.endswith(\".txt\"):\n",
    "        with open(path + filename, \"r\", encoding= 'utf-8') as file:\n",
    "            data = file.read()\n",
    "            lines2.append(data)\n",
    "\n",
    "path = '2社會/'\n",
    "lines3 =[]\n",
    "for filename in os.listdir(path):\n",
    "    if os.path.isfile(path + filename) and filename.endswith(\".txt\"):\n",
    "        with open(path + filename, \"r\", encoding= 'utf-8') as file:\n",
    "            data = file.read()\n",
    "            lines3.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義分詞和打標簽函數preprocess_text\n",
    "#參數content_lines即為上面轉換的list\n",
    "#參數sentences是定義的空list，用來儲存打標簽之後的數據\n",
    "#參數category 是類型標簽\n",
    "def preprocess_text(content_lines, classlabel):\n",
    "    sentences =[]\n",
    "    categories = []\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs=jieba.lcut(line)\n",
    "            segs = [v for v in segs if not str(v).isdigit()]#去數字\n",
    "                                                            #filter() 函数用於過濾序列，過濾掉不符合條件的元素，返回由符合条件元素组成的新列表。\n",
    "            segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "            segs = list(filter(lambda x:len(x)>1, segs)) #長度為1的字符\n",
    "            segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用詞\n",
    "            sentences.append(segs)\n",
    "            categories.append(classlabel)\n",
    "        except Exception:\n",
    "            print(line)\n",
    "            continue\n",
    "    \n",
    "    return sentences, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = preprocess_text(lines1, 0)  #把第一類的文章分成第 0 類\n",
    "X2, y2 = preprocess_text(lines2, 1)  #把第二類的文章分成第 1 類\n",
    "X3, y3 = preprocess_text(lines3, 2)\n",
    "X = X1 + X2 + X3  #把類別加起來\n",
    "y = y1 + y2 + y3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽取詞向量特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "import gensim\n",
    "from gensim import utils\n",
    "from gensim import corpora,models\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary(X)  #開始做字典\n",
    "corpus = [dictionary.doc2bow(text) for text in X]  #轉換成詞袋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.TfidfModel(corpus)  #將15篇文章建模  , 改成TFIDF VALUE\n",
    "corpus = [text for text in model[corpus]]\n",
    "X = gensim.matutils.corpus2dense(corpus, num_terms=len(dictionary.token2id)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(np.array(y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split   #訓練 & 測試資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model Summary: \n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 128)               7054976   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,055,363\n",
      "Trainable params: 7,055,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2025 samples, validate on 225 samples\n",
      "Epoch 1/30\n",
      " - 212s - loss: 0.8768 - accuracy: 0.5768 - val_loss: 0.6637 - val_accuracy: 0.5733\n",
      "Epoch 2/30\n",
      " - 212s - loss: 0.5562 - accuracy: 0.6632 - val_loss: 0.5615 - val_accuracy: 0.4444\n",
      "Epoch 3/30\n",
      " - 215s - loss: 0.4848 - accuracy: 0.6904 - val_loss: 0.5622 - val_accuracy: 0.4356\n",
      "Epoch 4/30\n",
      " - 217s - loss: 0.4587 - accuracy: 0.6923 - val_loss: 0.5924 - val_accuracy: 0.4311\n",
      "Epoch 5/30\n",
      " - 245s - loss: 0.4406 - accuracy: 0.7017 - val_loss: 0.6529 - val_accuracy: 0.4267\n",
      "Epoch 6/30\n",
      " - 251s - loss: 0.4248 - accuracy: 0.7042 - val_loss: 0.7314 - val_accuracy: 0.4267\n",
      "Epoch 7/30\n",
      " - 213s - loss: 0.4115 - accuracy: 0.7047 - val_loss: 0.8206 - val_accuracy: 0.4178\n",
      "Epoch 8/30\n",
      " - 208s - loss: 0.3991 - accuracy: 0.7077 - val_loss: 0.9206 - val_accuracy: 0.4267\n",
      "Epoch 9/30\n",
      " - 231s - loss: 0.3898 - accuracy: 0.7077 - val_loss: 1.0222 - val_accuracy: 0.4178\n",
      "Epoch 10/30\n",
      " - 237s - loss: 0.3819 - accuracy: 0.7096 - val_loss: 1.1183 - val_accuracy: 0.4222\n",
      "Epoch 11/30\n",
      " - 244s - loss: 0.3746 - accuracy: 0.7131 - val_loss: 1.2189 - val_accuracy: 0.4178\n",
      "Epoch 12/30\n",
      " - 232s - loss: 0.3700 - accuracy: 0.6948 - val_loss: 1.3159 - val_accuracy: 0.4178\n",
      "Epoch 13/30\n",
      " - 237s - loss: 0.3652 - accuracy: 0.7067 - val_loss: 1.4020 - val_accuracy: 0.4133\n",
      "Epoch 14/30\n",
      " - 256s - loss: 0.3611 - accuracy: 0.6973 - val_loss: 1.4961 - val_accuracy: 0.4133\n",
      "Epoch 15/30\n",
      " - 214s - loss: 0.3568 - accuracy: 0.7012 - val_loss: 1.5901 - val_accuracy: 0.4133\n",
      "Epoch 16/30\n",
      " - 205s - loss: 0.3555 - accuracy: 0.6973 - val_loss: 1.6566 - val_accuracy: 0.4133\n",
      "Epoch 17/30\n",
      " - 231s - loss: 0.3522 - accuracy: 0.6874 - val_loss: 1.7344 - val_accuracy: 0.4133\n",
      "Epoch 18/30\n",
      " - 194s - loss: 0.3491 - accuracy: 0.6998 - val_loss: 1.8218 - val_accuracy: 0.4133\n",
      "Epoch 19/30\n",
      " - 195s - loss: 0.3474 - accuracy: 0.6864 - val_loss: 1.8934 - val_accuracy: 0.4044\n",
      "Epoch 20/30\n",
      " - 210s - loss: 0.3455 - accuracy: 0.6859 - val_loss: 1.9651 - val_accuracy: 0.4044\n",
      "Epoch 21/30\n",
      " - 231s - loss: 0.3431 - accuracy: 0.6825 - val_loss: 2.0354 - val_accuracy: 0.4089\n",
      "Epoch 22/30\n"
     ]
    }
   ],
   "source": [
    "#Build the model  #建造模型keras語法\n",
    "#input_shape=(A,B)，可建構2D層，也能只運用來表是一維層：input_shape=(A,)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=(55116), activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, input_dim=(55116), activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, input_dim=(55116), activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, input_dim=(55116), activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "# Adam optimizer with learning rate of 0.001\n",
    "optimizer = Adam(lr=1e-4)  # optimizer = Adam(lr=0.001) 訓練參數\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#('optimizer' - 目標函數)  ('metrics' - 準確性)\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())  #會告訴你有幾個參數要預測\n",
    "\n",
    "\n",
    "import time  # 想要知道要跑多久 \n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model - 調整參數在這邊調整\n",
    "\n",
    "train = model.fit(X_train, y_train, verbose=2, batch_size=10, epochs=30, validation_split=0.1)\n",
    "\n",
    "# epochs 跑幾圈\n",
    "# batch_size 更新權重單元\n",
    "#validation_split 驗證資料 = 0.1 (抽10%)  (把訓練的資料再抽一點出來 \n",
    "#verbose=2 要不要看過程 -0(不看detail)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Test on unseen data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))  # loss \n",
    "print('Final test set accuracy: {:4f}'.format(results[1])) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
